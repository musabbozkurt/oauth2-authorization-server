server:
  port: '9000'

spring:
  datasource:
    url: ${SPRING_DATASOURCE_URL:jdbc:mariadb://localhost:3306/oauth2_authorization_server}
    username: ${DB_USERNAME:mb_test}
    password: ${DB_PASSWORD:test}
    driver-class-name: org.mariadb.jdbc.Driver

  flyway:
    enabled: true
    baseline-version: 0
    baseline-on-migrate: true
    schemas: oauth2_authorization_server
    table: schema_version
    validate-on-migrate: true

  jpa:
    properties:
      hibernate:
        format_sql: true
        default_schema: oauth2_authorization_server
    defer-datasource-initialization: false # https://stackoverflow.com/a/69235286 -> https://docs.spring.io/spring-boot/docs/current/reference/html/howto.html
    hibernate:
      ddl-auto: validate
    generate-ddl: false
    show-sql: true
    open-in-view: false

  docker:
    compose:
      enabled: false

  ai:
    openai:
      api-key: ${DEEP_SEEK_API_KEY}
      base-url: https://api.deepseek.com
      chat:
        options:
          model: ai/gemma3:4B-Q4_K_M
        base-url: http://localhost:12434/engines/llama.cpp
    # NEW in 2.0: Official OpenAI Java SDK
    openai-sdk:
      api-key: ${OPENAI_API_KEY:openai-api-key}
      chat:
        options:
          model: gpt-4o
      # Multi-provider support (same code, different backend):
      # Azure OpenAI:
      #   base-url: https://<deployment>.openai.azure.com
      #   microsoft-deployment-name: <deployment-name>
      # GitHub Models:
      #   base-url: https://models.inference.ai.azure.com
      #   api-key: github_pat_XXX

    # NEW in 2.0: Anthropic Citations & Skills API
    anthropic:
      api-key: ${ANTHROPIC_API_KEY:anthropic-api-key}
      timeout: 600s
      chat:
        options:
          model: claude-sonnet-4-5

    # NEW in 2.0: Google GenAI (Gemini) integration
    google:
      genai:
        api-key: ${GOOGLE_GENAI_API_KEY:google-api-key}
        chat:
          options:
            model: gemini-2.0-flash

    # NEW in 2.0: Redis Chat Memory configuration
    chat:
      memory:
        repository:
          redis:
            key-prefix: "spring-ai-chat:"
            time-to-live: 1h
    ollama:
      chat:
        model: deepseek-r1:7b
    vectorstore:
      mariadb:
        initialize-schema: true
        distance-type: COSINE
        dimensions: 1536
    mcp:
      server:
        name: webmvc-mcp-server
        version: 1.0.0
        type: SYNC

  main:
    banner-mode: off # NOTE: The banner and the console logging must be disabled to allow the STDIO transport to work

  ldap:
    urls: ${SPRING_LDAP_URL:ldap://localhost:10389}
    password: ${SPRING_LDAP_PASSWORD:admin_pass}
    user-dn: ${SPRING_LDAP_USER_DN:cn=admin,ou=people,dc=mbexample,dc=com}
    user-search-base: ${SPRING_LDAP_USER_SEARCH_BASE:ou=people,dc=mbexample,dc=com}
    user-search-filter: ${SPRING_LDAP_USER_SEARCH_FILTER:(cn={0})}

logging:
  level:
    org.springframework.security: info

springdoc:
  api-docs:
    path: /v3/api-docs # http://localhost:9000/v3/api-docs
  swagger-ui:
    path: /swagger-ui.html # http://localhost:9000/swagger-ui/index.html
    csrf:
      enabled: true

openapi:
  title: ${OPENAPI_TITLE:OAuth2 Authorization Server}
  description: ${OPENAPI_DESCRIPTION:This lists all the OAuth2 Authorization Server API Calls. The Calls are OAuth2 secured, so please use your Client ID and Secret to test them out.}
  version: ${OPENAPI_VERSION:v1.0}
  oauth-flow:
    token-url: ${OPENAPI_OAUTH_FLOW_TOKEN_URL:/oauth2/token}

environment-namespace: server

minio:
  endpoint: ${MINIO_ENDPOINT:http://localhost:9091}
  accessKey: ${MINIO_ACCESS_KEY:minio-admin}
  secretKey: ${MINIO_SECRET_KEY:minio-password}
  bucket: mb-bucket

management:
  endpoints:
    web:
      exposure:
        include: health, info, metrics, loggers, prometheus
  tracing:
    sampling:
      probability: 1.0 # 100% sampling
    export:
      zipkin:
        endpoint: ${ZIPKIN_ENDPOINT:http://localhost:9411/api/v2/spans}
  otlp:
    metrics:
      export:
        url: http://localhost:4318/v1/metrics
  opentelemetry:
    tracing:
      export:
        otlp:
          endpoint: http://localhost:4318/v1/traces
    logging:
      export:
        otlp:
          endpoint: http://localhost:4318/v1/logs
